# Component 2 - generate column.description

- Problem: Column Name e.g. `1` converted into `vectors` - is not good for similarity search
- Purpose of this step - generate column description

```text
- 1. Input/Output
- 2. Docker - LLM
- 3. Folder Structure
- 4. Performance Consideration
```

## 1. Input / Output

### Input - Keys + JSON

```text
ClassifiedCompaniesRelational_Jul2025__ClassifiedCompaniesRelational__CompanyCategory
ClassifiedCompaniesRelational_Jul2025__ClassifiedCompaniesRelational__CompanyName
```

### Output

```json
{
  "ClassifiedCompaniesRelational_Jul2025__ClassifiedCompaniesRelational__CompanyName": {
    "column_name": "CompanyName",
    "data_type": "VARCHAR",
    "database_name": "ClassifiedCompaniesRelational_Jul2025",
    "null_percentage": 0.0,
    "sample_data": [
      "HOUSE OF MIAHS LIMITED",
      "KONSTNAR LIMITED",
      "B-SPOKE AUTOMOTIVE LIMITED",
      "CLARITY ULTRASOUND LIMITED",
      "FUNLINX UK LTD"
    ],
    "table_name": "ClassifiedCompaniesRelational",
    "total_rows": 10204100,
    "unique_count": 10026123,
    // generated by LLM
    "description": "CompanyName - name of a registered company"
  }
}
```

### Data Consistency

```json
{
  "model": "llama3.2:3b",
  "prompt": prompt,
  "stream": false,
  "options": {
    "temperature": 0.1,
    "top_p": 0.9,
    "num_predict": 100
  }
}
```

| Setting     | Value      | Purpose                                              |
|-------------|------------|------------------------------------------------------|
| Temperature | Low        | Low randomness                                       |
| Top_p       | Configured | Cumulative probability threshold for token selection |
| num_predict | ~100       | Output Token Limit - max_tokens                      |

```text
Top_p:

All Tokens: [A:0.4] [B:0.3] [C:0.2] [D:0.05] [E:0.03] [F:0.02]
            ↓
top_p=0.9   [A:0.4] [B:0.3] [C:0.2] ← stops here (0.4+0.3+0.2=0.9)
            ↓
Sample from {A, B, C} only
```

#### Prompt

```text
Generate a description for this database column:

Column: {column_name}
Table: {table_name}  
Data Type: {data_type}
{sample_text}

Provide only the description following the format: "{column_name} - [brief definition]"
```

## 2. Docker - LLM

| Name   | Ports | Image                         | Type        | GPU |
|--------|-------|-------------------------------|-------------|-----|
| llama3 | 30020 | mingzilla/ollama-llama3:1.0.0 | completions | Y   |

## 3. Folder Structure - Supports Reusing Processed Data

```text
[data]
|-- 2025-07  ------ Previous
|   |-- v1.json
|   |-- keys.txt
|   +-- v2.json
|
+-- 2025-08  ------ Current
    |-- v1.json
    |-- keys.txt
    +-- v2.json

[src]
|-- step001  ------ Step 1 Code
|-- step002  ------ Step 2 Code
|-- step003

[scripts]
|-- step001  ------ Run Step 1 Python Code
|-- step002
|-- step003
```

## 4. Performance Consideration

## 4.1. Skip LLM Request

```text
key -> get json from `2025-07/v2.json` - json exists?
    - YES - Use -- It already has description 
    - NO  - LLM -> description 
```

## 4.2. Memory Strategy

- Small Count (e.g. < 1000 columns) - in memory processing -> dump into a file
- IO once - file handling, synchronization
